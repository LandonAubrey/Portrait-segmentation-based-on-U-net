{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于U-Net的人像分割模型\n",
    " \n",
    "本项目实现了一个基于U-Net架构的人像分割模型，用于从图像中提取人物前景。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 安装必要的库\n",
    "# !pip install beautifulsoup4 -t /home/aistudio/external-libraries --no-user\n",
    "# !pip install albumentations -t /home/aistudio/external-libraries --no-user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 导入所需的库\n",
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import json\n",
    "import paddle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from paddle.io import Dataset, DataLoader\n",
    "import cv2\n",
    "import paddle.vision.transforms as T\n",
    "import time\n",
    "from tqdm.notebook import tqdm  # 使用notebook版本的tqdm\n",
    "from visualdl import LogWriter\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "# import albumentations\n",
    "\n",
    "# 确保paddle能够使用GPU (如果可用)\n",
    "paddle.device.set_device('gpu:0' if paddle.device.is_compiled_with_cuda() else 'cpu')\n",
    "print(f\"使用设备: {paddle.device.get_device()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pylab import mpl\n",
    "\n",
    "mpl.rcParams['font.sans-serif'] = ['SimHei']\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## 数据准备\n",
    "# 首先解压数据集到工作目录\n",
    "\n",
    "# 创建工作目录并解压数据集\n",
    "# !mkdir -p /home/aistudio/work/matting_human_half # -p 确保递归创建父目录\n",
    "# !unzip -q data/data338285/matting_human_half.zip -d /home/aistudio/work/matting_human_half\n",
    "\n",
    "# 检查解压后的文件结构\n",
    "!ls -la /home/aistudio/work/matting_human_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 数据集类定义\n",
    "# 加载和预处理人像分割数据集\n",
    "#   读取RGB图像和对应的Alpha遮罩\n",
    "#   划分训练和验证集\n",
    "\n",
    "class MattingHumanDataset(Dataset):\n",
    "    def __init__(self, root_dir, is_train=True, transform=None, img_size=(256, 256)):\n",
    "        \"\"\"\n",
    "        人像分割数据集类\n",
    "        \n",
    "        参数:\n",
    "            root_dir (str): 数据集根目录\n",
    "            is_train (bool): 是否为训练集\n",
    "            transform: 数据预处理/增强方法\n",
    "            img_size (tuple): 目标图像尺寸，默认(256, 256)\n",
    "        \"\"\"\n",
    "        super(MattingHumanDataset, self).__init__()\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        self.img_size = img_size\n",
    "        self.image_paths = []\n",
    "        self.mask_paths = []\n",
    "\n",
    "        # 获取所有图像和掩码的路径\n",
    "        self._collect_files()\n",
    "        \n",
    "        # 显示数据集文件夹结构\n",
    "        print(f\"数据集根目录: {root_dir}\")\n",
    "        print(f\"图像文件夹: {os.path.join(root_dir, 'clip_img')}\")\n",
    "        print(f\"掩码文件夹: {os.path.join(root_dir, 'matting')}\")\n",
    "\n",
    "        # 划分训练集和验证集\n",
    "        if is_train:\n",
    "            self.image_paths = self.image_paths[:int(len(self.image_paths) * 0.8)]\n",
    "            self.mask_paths = self.mask_paths[:int(len(self.mask_paths) * 0.8)]\n",
    "        else:\n",
    "            self.image_paths = self.image_paths[int(len(self.image_paths) * 0.8):]\n",
    "            self.mask_paths = self.mask_paths[int(len(self.mask_paths) * 0.8):]\n",
    "\n",
    "        print(f\"{'训练' if is_train else '验证'}数据集: {len(self.image_paths)} 图像\")\n",
    "        \n",
    "        # 样本数为0时抛出异常\n",
    "        if len(self.image_paths) == 0:\n",
    "            print(f\"数据集为空 root_dir={self.root_dir}, is_train={self.is_train}\")\n",
    "            raise ValueError(\"未找到任何样本，请检查数据集路径和结构！\")\n",
    "\n",
    "    # 收集图像和掩码的路径\n",
    "    def _collect_files(self):\n",
    "        # 图像所在文件夹路径\n",
    "        img_root = os.path.join(self.root_dir, \"clip_img\")\n",
    "        # 掩码所在文件夹路径\n",
    "        mask_root = os.path.join(self.root_dir, \"matting\")\n",
    "\n",
    "        # 检查目录是否存在\n",
    "        if not os.path.exists(img_root):\n",
    "            print(f\"图像文件夹不存在: {img_root}\")\n",
    "        if not os.path.exists(mask_root):\n",
    "            print(f\"掩码文件夹不存在: {mask_root}\")\n",
    "\n",
    "        # 遍历所有编号文件夹\n",
    "        for folder_id in os.listdir(img_root):\n",
    "            # 一级子文件夹路径\n",
    "            folder_path = os.path.join(img_root, folder_id)\n",
    "            # 跳过不存在的目录，遍历文件夹时过滤无效路径\n",
    "            if not os.path.isdir(folder_path):\n",
    "                continue\n",
    "\n",
    "            # 遍历所有clip_文件夹\n",
    "            for clip_folder in os.listdir(folder_path):\n",
    "                clip_path = os.path.join(folder_path, clip_folder)\n",
    "                if not os.path.isdir(clip_path):\n",
    "                    continue\n",
    "\n",
    "                # 构建对应的matting文件夹名（将clip_替换为matting_）\n",
    "                matting_folder = clip_folder.replace('clip_', 'matting_')\n",
    "                # 对应的掩码文件夹路径\n",
    "                mask_clip_path = os.path.join(mask_root, folder_id, matting_folder)\n",
    "            \n",
    "                if not os.path.exists(mask_clip_path):\n",
    "                    print(f\"掩码文件夹不存在: {mask_clip_path}\")  # 可选：添加调试信息\n",
    "                    continue\n",
    "\n",
    "                # 遍历所有图像文件\n",
    "                for img_file in os.listdir(clip_path):\n",
    "                    if not img_file.endswith('.jpg'):\n",
    "                        continue\n",
    "\n",
    "                    img_path = os.path.join(clip_path, img_file)\n",
    "                    # 掩码文件应该是同名但扩展名为png\n",
    "                    mask_file = img_file.replace('.jpg', '.png')\n",
    "                    mask_path = os.path.join(mask_clip_path, mask_file)\n",
    "\n",
    "                    if os.path.exists(mask_path):\n",
    "                        self.image_paths.append(img_path)\n",
    "                        self.mask_paths.append(mask_path)\n",
    "\n",
    "    # 返回数据集样本数量\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        mask_path = self.mask_paths[idx]\n",
    "\n",
    "        # 读取图像和掩码\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 读取PNG掩码图像，保留所有通道(包括Alpha通道)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        # 提取Alpha通道\n",
    "        if len(mask.shape) == 3 and mask.shape[2] == 4:  # RGBA格式\n",
    "            # 提取Alpha通道\n",
    "            alpha_mask = mask[:, :, 3]\n",
    "        elif len(mask.shape) == 3:  # RGB格式，无Alpha通道\n",
    "            # 转为灰度图\n",
    "            alpha_mask = cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY)\n",
    "        else:  # 已经是灰度图\n",
    "            alpha_mask = mask\n",
    "\n",
    "        # 归一化 (0-255 -> 0-1)\n",
    "        alpha_mask = alpha_mask.astype(np.float32) / 255.0\n",
    "\n",
    "        # 数据增强\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=alpha_mask)\n",
    "            image = augmented['image']\n",
    "            alpha_mask = augmented['mask']\n",
    "        else:\n",
    "            # 基本预处理\n",
    "            image = cv2.resize(image, self.img_size)\n",
    "            alpha_mask = cv2.resize(alpha_mask, self.img_size, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            # 转换为适合PaddlePaddle的格式\n",
    "            image = image.transpose(2, 0, 1).astype('float32') / 255.0\n",
    "            alpha_mask = alpha_mask.astype('float32')\n",
    "            alpha_mask = np.expand_dims(alpha_mask, axis=0)\n",
    "\n",
    "        return paddle.to_tensor(image), paddle.to_tensor(alpha_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_transform = None\n",
    "val_transform = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 查看数据集样本\n",
    "# 可视化几个训练样本，以确保数据加载正确\n",
    "\n",
    "try:\n",
    "    data_root = '/home/aistudio/work/matting_human_half'\n",
    "    viz_dataset = MattingHumanDataset(\n",
    "        root_dir=data_root,\n",
    "        is_train=True,\n",
    "        transform=None  # 不使用变换以便于可视化原始数据\n",
    "    )\n",
    "    \n",
    "    # 显示几个样本\n",
    "    fig, axs = plt.subplots(3, 2, figsize=(12, 15))\n",
    "    \n",
    "    for i in range(3):\n",
    "        if i < len(viz_dataset):\n",
    "            # 获取样本\n",
    "            image, mask = viz_dataset[i]\n",
    "            \n",
    "            # 转换回numpy以便于显示\n",
    "            image_np = image.numpy().transpose(1, 2, 0)\n",
    "            mask_np = mask.numpy().squeeze()\n",
    "            \n",
    "            # 显示图像\n",
    "            axs[i, 0].imshow(image_np)\n",
    "            axs[i, 0].set_title(f\"Original Image #{i+1}\")\n",
    "            axs[i, 0].axis('off')\n",
    "            \n",
    "            # 显示掩码\n",
    "            axs[i, 1].imshow(mask_np, cmap='gray')\n",
    "            axs[i, 1].set_title(f\"Partition mask #{i+1}\")\n",
    "            axs[i, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"数据集可视化失败: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# U-Net模型定义\n",
    "\n",
    "# U-Net的基本构建块：双重卷积\n",
    "class DoubleConv(nn.Layer):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2D(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2D(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2D(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2D(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "# U-Net模型\n",
    "class UNet(nn.Layer):\n",
    "    def __init__(self, n_channels=3, n_classes=1, bilinear=False):\n",
    "        \"\"\"\n",
    "        U-Net分割模型\n",
    "        \n",
    "        参数:\n",
    "            n_channels (int): 输入通道数\n",
    "            n_classes (int): 输出通道数/类别数\n",
    "            bilinear (bool): 是否使用双线性插值上采样\n",
    "        \"\"\"\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        # 编码器路径（下采样）\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = nn.Sequential(nn.MaxPool2D(2), DoubleConv(64, 128))\n",
    "        self.down2 = nn.Sequential(nn.MaxPool2D(2), DoubleConv(128, 256))\n",
    "        self.down3 = nn.Sequential(nn.MaxPool2D(2), DoubleConv(256, 512))\n",
    "        self.down4 = nn.Sequential(nn.MaxPool2D(2), DoubleConv(512, 1024))\n",
    "\n",
    "        # 解码器路径（上采样）\n",
    "        if bilinear:\n",
    "            self.up1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv_up1 = DoubleConv(1024 + 512, 512)\n",
    "\n",
    "            self.up2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv_up2 = DoubleConv(512 + 256, 256)\n",
    "\n",
    "            self.up3 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv_up3 = DoubleConv(256 + 128, 128)\n",
    "\n",
    "            self.up4 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv_up4 = DoubleConv(128 + 64, 64)\n",
    "        else:\n",
    "            self.up1 = nn.Conv2DTranspose(1024, 512, kernel_size=2, stride=2)\n",
    "            self.conv_up1 = DoubleConv(1024, 512)\n",
    "\n",
    "            self.up2 = nn.Conv2DTranspose(512, 256, kernel_size=2, stride=2)\n",
    "            self.conv_up2 = DoubleConv(512, 256)\n",
    "\n",
    "            self.up3 = nn.Conv2DTranspose(256, 128, kernel_size=2, stride=2)\n",
    "            self.conv_up3 = DoubleConv(256, 128)\n",
    "\n",
    "            self.up4 = nn.Conv2DTranspose(128, 64, kernel_size=2, stride=2)\n",
    "            self.conv_up4 = DoubleConv(128, 64)\n",
    "\n",
    "        # 输出层\n",
    "        self.outc = nn.Conv2D(64, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 编码器路径\n",
    "        x1 = self.inc(x)        # [B, 64, H, W]\n",
    "        x2 = self.down1(x1)     # [B, 128, H/2, W/2]\n",
    "        x3 = self.down2(x2)     # [B, 256, H/4, W/4]\n",
    "        x4 = self.down3(x3)     # [B, 512, H/8, W/8]\n",
    "        x5 = self.down4(x4)     # [B, 1024, H/16, W/16]\n",
    "\n",
    "        # 解码器路径\n",
    "        if self.bilinear:\n",
    "            # 双线性插值上采样\n",
    "            x = self.up1(x5)\n",
    "            x = self.conv_up1(paddle.concat([x4, x], axis=1))\n",
    "\n",
    "            x = self.up2(x)\n",
    "            x = self.conv_up2(paddle.concat([x3, x], axis=1))\n",
    "\n",
    "            x = self.up3(x)\n",
    "            x = self.conv_up3(paddle.concat([x2, x], axis=1))\n",
    "\n",
    "            x = self.up4(x)\n",
    "            x = self.conv_up4(paddle.concat([x1, x], axis=1))\n",
    "        else:\n",
    "            # 转置卷积上采样\n",
    "            x = self.up1(x5)\n",
    "            # 处理特征图尺寸不匹配的情况\n",
    "            diff_h = x4.shape[2] - x.shape[2]\n",
    "            diff_w = x4.shape[3] - x.shape[3]\n",
    "\n",
    "            # 如果尺寸不匹配，进行填充\n",
    "            if diff_h > 0 or diff_w > 0:\n",
    "                x = F.pad(x, [diff_w // 2, diff_w - diff_w // 2,\n",
    "                              diff_h // 2, diff_h - diff_h // 2])\n",
    "\n",
    "            x = self.conv_up1(paddle.concat([x4, x], axis=1))\n",
    "\n",
    "            x = self.up2(x)\n",
    "            diff_h = x3.shape[2] - x.shape[2]\n",
    "            diff_w = x3.shape[3] - x.shape[3]\n",
    "            if diff_h > 0 or diff_w > 0:\n",
    "                x = F.pad(x, [diff_w // 2, diff_w - diff_w // 2,\n",
    "                              diff_h // 2, diff_h - diff_h // 2])\n",
    "            x = self.conv_up2(paddle.concat([x3, x], axis=1))\n",
    "\n",
    "            x = self.up3(x)\n",
    "            diff_h = x2.shape[2] - x.shape[2]\n",
    "            diff_w = x2.shape[3] - x.shape[3]\n",
    "            if diff_h > 0 or diff_w > 0:\n",
    "                x = F.pad(x, [diff_w // 2, diff_w - diff_w // 2,\n",
    "                              diff_h // 2, diff_h - diff_h // 2])\n",
    "            x = self.conv_up3(paddle.concat([x2, x], axis=1))\n",
    "\n",
    "            x = self.up4(x)\n",
    "            diff_h = x1.shape[2] - x.shape[2]\n",
    "            diff_w = x1.shape[3] - x.shape[3]\n",
    "            if diff_h > 0 or diff_w > 0:\n",
    "                x = F.pad(x, [diff_w // 2, diff_w - diff_w // 2,\n",
    "                              diff_h // 2, diff_h - diff_h // 2])\n",
    "            x = self.conv_up4(paddle.concat([x1, x], axis=1))\n",
    "\n",
    "        # 输出层\n",
    "        logits = self.outc(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 可视化模型架构\n",
    "model = UNet(n_channels=3, n_classes=1)\n",
    "print(f\"模型参数总数: {sum(p.numel() for p in model.parameters())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 损失函数定义\n",
    "# 使用混合损失函数：BCE损失 + Dice损失，以获得更好的分割效果\n",
    "\n",
    "# 定义Dice损失函数\n",
    "def dice_loss(pred, target):\n",
    "    \"\"\"\n",
    "    计算Dice损失（针对分割任务的特殊损失函数）\n",
    "    1 - Dice系数，其中Dice系数 = 2*|X∩Y|/(|X|+|Y|)\n",
    "    \n",
    "    参数:\n",
    "        pred: 预测掩码\n",
    "        target: 真实掩码\n",
    "    \"\"\"\n",
    "    smooth = 1.0\n",
    "    pred = paddle.nn.functional.sigmoid(pred)\n",
    "    intersection = paddle.sum(pred * target)\n",
    "    union = paddle.sum(pred) + paddle.sum(target)\n",
    "    dice_coef = (2.0 * intersection + smooth) / (union + smooth)\n",
    "    return 1.0 - dice_coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 模型训练函数\n",
    "# 定义训练函数，使用Adam优化器和学习率调度器\n",
    "def train_model(data_root, output_dir, batch_size=8, num_epochs=50, learning_rate=1e-4, img_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    训练U-Net分割模型\n",
    "    \n",
    "    参数:\n",
    "        data_root: 数据集根目录\n",
    "        output_dir: 输出目录，存放模型和日志\n",
    "        batch_size: 批次大小\n",
    "        num_epochs: 训练轮数 \n",
    "        learning_rate: 学习率\n",
    "        img_size: 图像尺寸\n",
    "    \n",
    "    返回:\n",
    "        best_model_path: 最佳模型的路径\n",
    "    \"\"\"\n",
    "    # 创建目录\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    log_dir = os.path.join(output_dir, \"logs\")\n",
    "    model_dir = os.path.join(output_dir, \"models\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # 日志记录器\n",
    "    logger = LogWriter(logdir=log_dir)\n",
    "\n",
    "    # 创建数据集\n",
    "    train_dataset = MattingHumanDataset(\n",
    "        root_dir=data_root,\n",
    "        is_train=True,\n",
    "        transform=train_transform,\n",
    "        img_size=img_size\n",
    "    )\n",
    "\n",
    "    val_dataset = MattingHumanDataset(\n",
    "        root_dir=data_root,\n",
    "        is_train=False,\n",
    "        transform=val_transform,\n",
    "        img_size=img_size\n",
    "    )\n",
    "\n",
    "    # 训练集或验证集为空时直接报错\n",
    "    if len(train_dataset) == 0:\n",
    "        raise ValueError(\"训练集为空，请检查数据集路径和结构！\")\n",
    "    if len(val_dataset) == 0:\n",
    "        raise ValueError(\"验证集为空，请检查数据集路径和结构！\")\n",
    "\n",
    "    # 数据加载器\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    # 初始化模型\n",
    "    model = UNet(n_channels=3, n_classes=1)\n",
    "\n",
    "    # 损失函数和优化器\n",
    "    bce_criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = paddle.optimizer.Adam(parameters=model.parameters(), learning_rate=learning_rate)\n",
    "\n",
    "    # 学习率衰减\n",
    "    scheduler = paddle.optimizer.lr.ReduceOnPlateau(\n",
    "        learning_rate=optimizer.get_lr(),\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        verbose=True\n",
    "    )\n",
    "    optimizer.set_lr_scheduler(scheduler)\n",
    "\n",
    "    # 训练循环\n",
    "    best_val_loss = float('inf')\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 记录训练历史\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'val_dice': [],\n",
    "        'val_iou': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_bce_loss = 0\n",
    "        train_dice_loss = 0\n",
    "\n",
    "        # 替换tqdm进度条为简单的批次进度打印\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} [Train] - Processing {len(train_loader)} batches...')\n",
    "        for batch_idx, (images, masks) in enumerate(train_loader):\n",
    "            # 每10个batch打印一次进度\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f'  Batch {batch_idx+1}/{len(train_loader)}')\n",
    "            \n",
    "            # 前向传播\n",
    "            outputs = model(images)\n",
    "\n",
    "            # 混合损失：BCE + Dice\n",
    "            bce = bce_criterion(outputs, masks)\n",
    "            dice = dice_loss(outputs, masks)\n",
    "            loss = bce + dice\n",
    "\n",
    "            # 反向传播和优化\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.clear_grad()\n",
    "\n",
    "            # 更新损失\n",
    "            train_loss += loss.item()\n",
    "            train_bce_loss += bce.item()\n",
    "            train_dice_loss += dice.item()\n",
    "\n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_bce_loss = 0\n",
    "        val_dice_loss = 0\n",
    "        val_dice_coef = 0\n",
    "        val_iou = 0\n",
    "\n",
    "        # 批次进度打印\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} [Valid] - Processing {len(val_loader)} batches...')\n",
    "        with paddle.no_grad():\n",
    "            for batch_idx, (images, masks) in enumerate(val_loader):\n",
    "                # 每10个batch打印一次进度\n",
    "                if batch_idx % 10 == 0:\n",
    "                    print(f'  Batch {batch_idx+1}/{len(val_loader)}')\n",
    "                \n",
    "                outputs = model(images)\n",
    "\n",
    "                # 计算验证集损失\n",
    "                bce = bce_criterion(outputs, masks)\n",
    "                dice = dice_loss(outputs, masks)\n",
    "                loss = bce + dice\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                val_bce_loss += bce.item()\n",
    "                val_dice_loss += dice.item()\n",
    "\n",
    "                # 计算指标\n",
    "                preds = paddle.nn.functional.sigmoid(outputs) > 0.5\n",
    "                # 将布尔类型转换为浮点类型\n",
    "                preds = preds.astype('float32')\n",
    "\n",
    "                # Dice系数\n",
    "                dice_coef = (2 * paddle.sum(preds * masks)) / (paddle.sum(preds) + paddle.sum(masks) + 1e-8)\n",
    "                val_dice_coef += dice_coef.item()\n",
    "\n",
    "                # IoU\n",
    "                intersection = paddle.sum(preds * masks)\n",
    "                union = paddle.sum(preds) + paddle.sum(masks) - intersection\n",
    "                iou = intersection / (union + 1e-8)\n",
    "                val_iou += iou.item()\n",
    "\n",
    "        # 更新学习率\n",
    "        scheduler.step(val_loss)\n",
    "        optimizer.step()\n",
    "\n",
    "        # 计算平均值\n",
    "        train_loss /= len(train_loader)\n",
    "        train_bce_loss /= len(train_loader)\n",
    "        train_dice_loss /= len(train_loader)\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_bce_loss /= len(val_loader)\n",
    "        val_dice_loss /= len(val_loader)\n",
    "        val_dice_coef /= len(val_loader)\n",
    "        val_iou /= len(val_loader)\n",
    "        \n",
    "        # 更新历史记录\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_dice'].append(val_dice_coef)\n",
    "        history['val_iou'].append(val_iou)\n",
    "\n",
    "        # 记录日志\n",
    "        logger.add_scalar('训练/总损失', train_loss, epoch)\n",
    "        logger.add_scalar('训练/BCE损失', train_bce_loss, epoch)\n",
    "        logger.add_scalar('训练/Dice损失', train_dice_loss, epoch)\n",
    "\n",
    "        logger.add_scalar('验证/总损失', val_loss, epoch)\n",
    "        logger.add_scalar('验证/BCE损失', val_bce_loss, epoch)\n",
    "        logger.add_scalar('验证/Dice损失', val_dice_loss, epoch)\n",
    "        logger.add_scalar('验证/Dice系数', val_dice_coef, epoch)\n",
    "        logger.add_scalar('验证/IoU', val_iou, epoch)\n",
    "\n",
    "        # 打印训练进度\n",
    "        print(f'\\n===== Epoch {epoch + 1}/{num_epochs} =====')\n",
    "        print(f'训练损失: {train_loss:.4f}, BCE: {train_bce_loss:.4f}, Dice: {train_dice_loss:.4f}')\n",
    "        print(f'验证损失: {val_loss:.4f}, BCE: {val_bce_loss:.4f}, Dice: {val_dice_loss:.4f}')\n",
    "        print(f'验证指标: Dice系数: {val_dice_coef:.4f}, IoU: {val_iou:.4f}')\n",
    "        print(f'学习率: {optimizer.get_lr():.6f}')\n",
    "        print(f'耗时: {time.time() - start_time:.2f}秒')\n",
    "        print('=' * 30)\n",
    "\n",
    "        # 保存模型\n",
    "        epoch_model_path = os.path.join(model_dir, f'epoch_{epoch + 1}.pdparams')\n",
    "        paddle.save(model.state_dict(), epoch_model_path)\n",
    "\n",
    "        # 保存最佳模型\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_path = os.path.join(model_dir, 'best_model.pdparams')\n",
    "            paddle.save(model.state_dict(), best_model_path)\n",
    "            print(f'最佳模型已保存! 验证损失: {val_loss:.4f}')\n",
    "    \n",
    "    # 训练完成后可视化训练过程\n",
    "    epochs = range(1, num_epochs + 1)\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(epochs, history['train_loss'], 'b-', label='train_loss')\n",
    "    plt.plot(epochs, history['val_loss'], 'r-', label='val_loss')\n",
    "    plt.title('train_val_loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(epochs, history['val_dice'], 'g-')\n",
    "    plt.title('Verify Dice coefficient')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Dice coefficient')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(epochs, history['val_iou'], 'm-')\n",
    "    plt.title('Verify IoU')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('IoU')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'training_history.png'))\n",
    "    plt.show()\n",
    "\n",
    "    print('训练完成!')\n",
    "    return os.path.join(model_dir, 'best_model.pdparams')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 模型评估函数\n",
    "\n",
    "def evaluate_model(model_path, data_root, batch_size=16):\n",
    "    \"\"\"\n",
    "    评估训练好的模型\n",
    "    \n",
    "    参数:\n",
    "        model_path: 模型权重文件路径\n",
    "        data_root: 数据集根目录\n",
    "        batch_size: 批次大小\n",
    "    \n",
    "    返回:\n",
    "        mean_dice: 平均Dice系数\n",
    "        mean_iou: 平均IoU\n",
    "    \"\"\"\n",
    "    # 加载模型\n",
    "    model = UNet(n_channels=3, n_classes=1)\n",
    "    model.set_state_dict(paddle.load(model_path))\n",
    "    model.eval()\n",
    "\n",
    "    # 创建验证数据集\n",
    "    test_dataset = MattingHumanDataset(\n",
    "        root_dir=data_root,\n",
    "        is_train=False,\n",
    "        transform=val_transform\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    dice_scores = []\n",
    "    iou_scores = []\n",
    "\n",
    "    print(\"开始评估...\")\n",
    "    print(f\"评估 - Processing {len(test_loader)} batches...\")\n",
    "    with paddle.no_grad():\n",
    "        for batch_idx, (images, masks) in enumerate(test_loader):\n",
    "            # 每10个batch打印一次进度\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f'  Batch {batch_idx+1}/{len(test_loader)}')\n",
    "            \n",
    "            outputs = model(images)\n",
    "            preds = paddle.nn.functional.sigmoid(outputs) > 0.5\n",
    "            # 将布尔类型转换为浮点类型\n",
    "            preds = preds.astype('float32')\n",
    "\n",
    "            # 计算 Dice 系数\n",
    "            dice = (2 * paddle.sum(preds * masks)) / (paddle.sum(preds) + paddle.sum(masks) + 1e-8)\n",
    "            dice_scores.append(dice.item())\n",
    "\n",
    "            # 计算 IoU\n",
    "            intersection = paddle.sum(preds * masks)\n",
    "            union = paddle.sum(preds) + paddle.sum(masks) - intersection\n",
    "            iou = intersection / (union + 1e-8)\n",
    "            iou_scores.append(iou.item())\n",
    "\n",
    "    mean_dice = sum(dice_scores) / len(dice_scores)\n",
    "    mean_iou = sum(iou_scores) / len(iou_scores)\n",
    "\n",
    "    print(f'评估结果:')\n",
    "    print(f'平均 Dice 系数: {mean_dice:.4f}')\n",
    "    print(f'平均 IoU: {mean_iou:.4f}')\n",
    "    \n",
    "    # 可视化评估结果\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(dice_scores, bins=20, alpha=0.7)\n",
    "    plt.axvline(mean_dice, color='r', linestyle='--', label=f'average value: {mean_dice:.4f}')\n",
    "    plt.title('Dice coefficient distribution')\n",
    "    plt.xlabel('Dice coefficient')\n",
    "    plt.ylabel('Number of samples')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(iou_scores, bins=20, alpha=0.7)\n",
    "    plt.axvline(mean_iou, color='r', linestyle='--', label=f'average value: {mean_iou:.4f}')\n",
    "    plt.title('IoU distribution')\n",
    "    plt.xlabel('IoU')\n",
    "    plt.ylabel('Number of samples')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return mean_dice, mean_iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 图片可视化函数\n",
    "\n",
    "def visualize_results(model_path, test_image_path, output_path, img_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    可视化单张图片的分割结果\n",
    "    \n",
    "    参数:\n",
    "        model_path: 模型权重文件路径\n",
    "        test_image_path: 测试图像路径\n",
    "        output_path: 输出图像保存路径\n",
    "        img_size: 处理图像尺寸\n",
    "    \"\"\"\n",
    "    # 加载模型\n",
    "    model = UNet(n_channels=3, n_classes=1)\n",
    "    model.set_state_dict(paddle.load(model_path))\n",
    "    model.eval()\n",
    "\n",
    "    # 读取和预处理图像\n",
    "    image = cv2.imread(test_image_path)\n",
    "    if image is None:\n",
    "        print(f\"无法读取图像: {test_image_path}\")\n",
    "        return\n",
    "        \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 保存原图\n",
    "    orig_img = image.copy()\n",
    "\n",
    "    # 预处理为网络输入格式\n",
    "    image = cv2.resize(image, img_size)\n",
    "    processed_img = image.copy()\n",
    "\n",
    "    image = image.transpose(2, 0, 1).astype('float32') / 255.0\n",
    "    image = paddle.to_tensor(image).unsqueeze(0)\n",
    "\n",
    "    # 预测\n",
    "    with paddle.no_grad():\n",
    "        output = model(image)\n",
    "        pred = paddle.nn.functional.sigmoid(output) > 0.5\n",
    "\n",
    "    # 将预测结果转换为图像\n",
    "    pred_mask = pred.squeeze().numpy()\n",
    "    pred_mask = (pred_mask * 255).astype(np.uint8)\n",
    "    pred_mask = cv2.resize(pred_mask, (orig_img.shape[1], orig_img.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # 创建原图上的蒙版显示\n",
    "    overlay = orig_img.copy()\n",
    "    alpha = 0.4  # 透明度\n",
    "    \n",
    "    # 在原图上应用绿色半透明蒙版\n",
    "    mask_colored = np.zeros_like(orig_img)\n",
    "    mask_colored[pred_mask > 0] = [0, 255, 0]  # 绿色蒙版\n",
    "    overlay = cv2.addWeighted(orig_img, 1-alpha, mask_colored, alpha, 0)\n",
    "    \n",
    "    # 创建分割边缘\n",
    "    contours, _ = cv2.findContours(pred_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    edge_overlay = orig_img.copy()\n",
    "    cv2.drawContours(edge_overlay, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "    # 创建透明背景的人像（RGBA格式）\n",
    "    portrait_only = np.zeros((orig_img.shape[0], orig_img.shape[1], 4), dtype=np.uint8)\n",
    "    portrait_only[:, :, :3] = orig_img  # 复制RGB通道\n",
    "    portrait_only[:, :, 3] = pred_mask  # Alpha通道使用分割掩码\n",
    "\n",
    "    # 保存结果 - 1行5列布局\n",
    "    plt.figure(figsize=(20, 4))\n",
    "\n",
    "    plt.subplot(1, 5, 1)\n",
    "    plt.imshow(orig_img)\n",
    "    plt.title('image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 5, 2)\n",
    "    plt.imshow(pred_mask, cmap='gray')\n",
    "    plt.title('mask')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 5, 3)\n",
    "    plt.imshow(overlay)\n",
    "    plt.title('Overlay results')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 5, 4)\n",
    "    plt.imshow(edge_overlay)\n",
    "    plt.title('Edge segmentation')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 5, 5)\n",
    "    plt.imshow(portrait_only)\n",
    "    plt.title('result')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # 单独保存抠图结果（透明背景PNG）\n",
    "    output_dir = os.path.dirname(output_path)\n",
    "    portrait_rgba_path = os.path.join(output_dir, 'portrait_transparent.png')\n",
    "    cv2.imwrite(portrait_rgba_path, cv2.cvtColor(portrait_only, cv2.COLOR_RGBA2BGRA))\n",
    "\n",
    "    print(f'可视化结果已保存至 {output_path}')\n",
    "    print(f'透明背景人像已保存至: {portrait_rgba_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 主函数：模型训练和评估\n",
    "\n",
    "def run_unet_segmentation(data_root='./work/matting_human_half',\n",
    "                          output_dir='./output',\n",
    "                          batch_size=8,\n",
    "                          num_epochs=10,\n",
    "                          learning_rate=1e-4,\n",
    "                          img_size=(256, 256),\n",
    "                          mode='all',\n",
    "                          model_path=None,\n",
    "                          test_image=None):\n",
    "    \"\"\"\n",
    "    运行人像分割U-Net模型的训练和测试\n",
    "    \n",
    "    参数:\n",
    "        data_root (str): 数据集根目录\n",
    "        output_dir (str): 输出目录\n",
    "        batch_size (int): 批次大小\n",
    "        num_epochs (int): 训练轮数\n",
    "        learning_rate (float): 学习率\n",
    "        img_size (tuple): 目标图像尺寸\n",
    "        mode (str): 运行模式，可选 'train', 'evaluate', 'visualize', 'all'\n",
    "        model_path (str): 模型路径(用于评估或可视化)\n",
    "        test_image (str): 测试图像路径(用于可视化)\n",
    "    \"\"\"\n",
    "    # 创建输出目录\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 根据运行模式执行不同操作\n",
    "    if mode in ['train', 'all']:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"开始训练模型...\")\n",
    "        print(\"=\"*50)\n",
    "        # 训练模型\n",
    "        best_model_path = train_model(\n",
    "            data_root=data_root,\n",
    "            output_dir=output_dir,\n",
    "            batch_size=batch_size,\n",
    "            num_epochs=num_epochs,\n",
    "            learning_rate=learning_rate,\n",
    "            img_size=img_size\n",
    "        )\n",
    "    else:\n",
    "        # 如果不训练，设置模型路径\n",
    "        best_model_path = model_path or os.path.join(output_dir, 'models', 'best_model.pdparams')\n",
    "        \n",
    "        if not os.path.exists(best_model_path):\n",
    "            print(f\"警告: 模型文件 {best_model_path} 不存在!\")\n",
    "            if mode != 'train':\n",
    "                return\n",
    "\n",
    "    # 评估模型\n",
    "    if mode in ['evaluate', 'all'] and os.path.exists(best_model_path):\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"开始评估模型...\")\n",
    "        print(\"=\"*50)\n",
    "        mean_dice, mean_iou = evaluate_model(\n",
    "            model_path=best_model_path,\n",
    "            data_root=data_root,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "        print(f\"\\n最终评估结果:\")\n",
    "        print(f\"平均Dice系数: {mean_dice:.4f}\")\n",
    "        print(f\"平均IoU: {mean_iou:.4f}\")\n",
    "\n",
    "    # 可视化结果\n",
    "    if mode in ['visualize', 'all'] and test_image and os.path.exists(best_model_path):\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"生成可视化结果...\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        output_path = os.path.join(output_dir, 'visualization.png')\n",
    "        visualize_results(\n",
    "            model_path=best_model_path,\n",
    "            test_image_path=test_image,\n",
    "            output_path=output_path,\n",
    "            img_size=img_size\n",
    "        )\n",
    "    elif mode in ['visualize', 'all'] and not test_image:\n",
    "        print(\"\\n警告: 未指定测试图像路径，跳过可视化步骤。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 开始训练和评估模型\n",
    "# 设置配置参数并运行模型\n",
    "\n",
    "# 设置参数\n",
    "config = {\n",
    "    # 数据路径\n",
    "    'data_root': '/home/aistudio/work/matting_human_half',\n",
    "    'output_dir': './output',\n",
    "\n",
    "    # 训练参数\n",
    "    'batch_size': 16,  # 减小批次大小以适应更大的图像\n",
    "    'num_epochs': 10,\n",
    "    'learning_rate': 1e-4,\n",
    "    'img_size': (512, 384),  # 保持原始宽高比的较大尺寸\n",
    "\n",
    "    # 运行模式\n",
    "    'mode': 'all',\n",
    "    'model_path': None,\n",
    "    'test_image': '/home/aistudio/work/matting_human_half/test.jpg'\n",
    "}\n",
    "\n",
    "# 运行模型训练和测试\n",
    "run_unet_segmentation(**config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 独立调用模型对结果的ke'shi'hua测试\n",
    "output_path = os.path.join('./output', 'visualization2.png')\n",
    "visualize_results(\n",
    "    model_path='./output/models/best_model.pdparams',\n",
    "    test_image_path='./work/matting_human_half/test2.jpg',\n",
    "    output_path=output_path,\n",
    "    img_size=(512,384)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
